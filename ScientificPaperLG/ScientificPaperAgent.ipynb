{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4625836e",
   "metadata": {},
   "source": [
    "## Scientific Paper Agent using LangGraph\n",
    "### Overview\n",
    "This project implements an intelligent research assistant that helps users navigate, understand, and analyze scientific literature using LangGraph and advanced language models. By combining various academic API with sophisticated paper processing techniques, it creates a seamless experience for researchers, students, and professionals working with academic papers.\n",
    "\n",
    "### Motivation \n",
    "Reduce the time people invest in R&D and reading, analyzing and synthesizing academic papers. \n",
    "Key Challenes include - \n",
    "* Extensive Time commitment \n",
    "* Inefficient search processes accross fragmented database ecosystems\n",
    "* Complex task synthesizingand connecting findings across multiple papers\n",
    "* Stay current with new publications\n",
    "\n",
    "## Key Components\n",
    "1. State-Driven Workflow Engine\n",
    "* StateGraph Architecture: Five-node system for orchestraded research.\n",
    "* Decision making node: Query intent analysis and routing.\n",
    "* Planning Node: Research Stategy formulation.\n",
    "* Tool Execution Node: Paper Retrievel and processing.\n",
    "* Judge Node: Quality validation and improvement cycles.\n",
    "\n",
    "2. Paper Processing Integration\n",
    "* Source Integration, CORE API for Comprehensive paper access.\n",
    "* Document Processing, PDF content extraction, Text Structure preservation.\n",
    "3. Analysis Workflow\n",
    "* State-aware processing pipeline\n",
    "* Multi-step validation gates\n",
    "* Quality-focused improvement cycles.\n",
    "* Human-in-the-loop validation options.\n",
    "\n",
    "\n",
    "### Method details\n",
    "#### The system requires\n",
    "\n",
    "- Gemini API Key.\n",
    "- CORE API key for paper retrieval. CORE is one of the larges online repositories for scientific papers, counting over 136 million papers, and offers a free API for personal use. A key can be requested here.\n",
    "#### Technical Architecture:\n",
    "\n",
    "- LangGraph for state orchestration.\n",
    "- PDFplumber for document processing.\n",
    "- Pydantic for structured data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a613481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "import time\n",
    "\n",
    "import pdfplumber\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, ClassVar, Sequence, TypedDict, Optional\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ[\"CORE_API_KEY\"] = os.getenv('CORE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb770d4",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "this cell contains the prompts used in the workflow\n",
    "\n",
    "the agent_prompt  contains a section how to use complex queries with CORE API enabling agent to solve more complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff595dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the initial decision making on how to reply to the user \n",
    "decision_making_prompt = \"\"\"\n",
    "You are an experienced scientific researcher.\n",
    "Your goal is to help the use with their scientific research.\n",
    "\n",
    "Based on the user query, decide if you need to perform a research or if you can answer the question directly.\n",
    "- You should perform a research if the user query requires any supporting evidence or information.\n",
    "- You should answer the question directly if the user query is a simple question that can be answered without any supporting evidence or information.\n",
    "\"\"\"\n",
    "\n",
    "# planning \n",
    "planning_prompt = \"\"\"\n",
    "You are an experienced scientific researcher.\n",
    "Your goal is to make a new step by step plan to help the user with their scientific research.\n",
    "\n",
    "Subtasks should not rely on any assumptions or guesses, but only rely on the information provided in the context or loop up for any additional information. \n",
    "if any feedback is provided about a previous answer, incorporate it into the new planning.\n",
    "# Tools\n",
    "\n",
    "for each substack, indicate the external tool required to complete the substack.\n",
    "Tools can be one of the following:\n",
    "{tools}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for the agent to answer the user query\n",
    "agent_prompt = \"\"\"\n",
    "#IDETITY AND PURPOSE\n",
    "\n",
    "You are an experienced scientific researcher.\n",
    "Your goal is to help the user with their scientific research. You have access to a set of external tools to complete your tasks.\n",
    "Follow the plan you wrote to successfully complete the task.\n",
    "Add extensive inline citations to support any claim made in the answer.\n",
    "\n",
    "\n",
    "# EXTERNAL KNOWLEDGE\n",
    "\n",
    "## CORE API\n",
    "\n",
    "The CORE API has a specific query language that allows you to explore a vast papers collection and perform complex queries. See the following table for a list of available operators:\n",
    "\n",
    "| Operator       | Accepted symbols         | Meaning                                                                                      |\n",
    "|---------------|-------------------------|----------------------------------------------------------------------------------------------|\n",
    "| And           | AND, +, space          | Logical binary and.                                                                           |\n",
    "| Or            | OR                     | Logical binary or.                                                                            |\n",
    "| Grouping      | (...)                  | Used to prioritise and group elements of the query.                                           |\n",
    "| Field lookup  | field_name:value       | Used to support lookup of specific fields.                                                    |\n",
    "| Range queries | fieldName(>, <,>=, <=) | For numeric and date fields, it allows to specify a range of valid values to return.         |\n",
    "| Exists queries| _exists_:fieldName     | Allows for complex queries, it returns all the items where the field specified by fieldName is not empty. |\n",
    "\n",
    "Use this table to formulate more complex queries filtering for specific papers, for example publication date/year.\n",
    "Here are the relevant fields of a paper object you can use to filter the results:\n",
    "{\n",
    "  \"authors\": [{\"name\": \"Last Name, First Name\"}],\n",
    "  \"documentType\": \"presentation\" or \"research\" or \"thesis\",\n",
    "  \"publishedDate\": \"2019-08-24T14:15:22Z\",\n",
    "  \"title\": \"Title of the paper\",\n",
    "  \"yearPublished\": \"2019\"\n",
    "}\n",
    "\n",
    "Example queries:\n",
    "- \"machine learning AND yearPublished:2023\"\n",
    "- \"maritime biology AND yearPublished>=2023 AND yearPublished<=2024\"\n",
    "- \"cancer research AND authors:Vaswani, Ashish AND authors:Bello, Irwan\"\n",
    "- \"title:Attention is all you need\"\n",
    "- \"mathematics AND _exists_:abstract\"\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for the judging step to evaluate the quality of the final answer\n",
    "judge_prompt = \"\"\"\n",
    "You are an expert scientific researcher.\n",
    "Your goal is to review the final answer you provided for a specific user query.\n",
    "\n",
    "Look at the conversation history between you and the user. Based on it, you need to decide if the final answer is satisfactory or not.\n",
    "\n",
    "A good final answer should:\n",
    "- Directly answer the user query. For example, it does not answer a question about a different paper or area of research.\n",
    "- Answer extensively the request from the user.\n",
    "- Take into account any feedback given through the conversation.\n",
    "- Provide inline sources to support any claim made in the answer.\n",
    "\n",
    "In case the answer is not good enough, provide clear and concise feedback on what needs to be improved to pass the evaluation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecade80d",
   "metadata": {},
   "source": [
    "## Utility classes and functions\n",
    "This cell contains the utility classes and functions used in the workflow. It includes a wrapper around the CORE API, the Pydantic models for the input and output of the nodes, and a few general-purpose functions.\n",
    "\n",
    "The CoreAPIWrapper class includes a retry mechanism to handle transient errors and make the workflow more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53d97493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreAPIWrapper(BaseModel):\n",
    "    \"\"\"Simple wrapper around CORE API\"\"\"\n",
    "    base_url: ClassVar[str] = \"https://api.core.ac.uk/v3\"\n",
    "    api_key: ClassVar[str] = os.getenv(\"CORE_API_KEY\")\n",
    "\n",
    "    top_k_results: int = Field(description=\"Top k results obtained by running a query on Core\", default=1)\n",
    "\n",
    "    def _get_search_response(self, query: str) -> dict:\n",
    "        http = urllib3.PoolManager()\n",
    "        # Retry mechanism to handle transient errors\n",
    "        max_retries = 5\n",
    "        for attempt in range(max_retries):\n",
    "            response = http.request(\n",
    "                'GET',\n",
    "                f\"{self.base_url}/search/outputs\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                fields = {\"q\":query, \"limit\":self.top_k_results}\n",
    "                )\n",
    "            if 200 <= response.status < 300:\n",
    "                return response.json()\n",
    "            elif attempt < max_retrie-1:\n",
    "                time.sleep(2 ** (attempt+2))\n",
    "            else:\n",
    "                raise Exception(f\"Error: {response.status} {response.reason}\")\n",
    "\n",
    "    def search(self, query: str) -> str:\n",
    "        response = self._get_search_response(query)\n",
    "        results = response.get(\"results\", [])\n",
    "        if not results:\n",
    "            return \"No relevant results were found\"\n",
    "\n",
    "        # Format the results in a string\n",
    "        docs = []\n",
    "        for result in results:\n",
    "            published_date_str = result.get('publishedDate') or result.get('yearPublished', '')\n",
    "            authors_str = ' and '.join([item['name'] for item in result.get('authors', [])])\n",
    "            docs.append((\n",
    "                f\"* ID: {result.get('id', '')},\\n\"\n",
    "                f\"* Title: {result.get('title', '')},\\n\"\n",
    "                f\"* Published Date: {published_date_str},\\n\"\n",
    "                f\"* Authors: {authors_str},\\n\"\n",
    "                f\"* Abstract: {result.get('abstract', '')},\\n\"\n",
    "                f\"* Paper URLs: {result.get('sourceFulltextUrls') or result.get('downloadUrl', '')}\"\n",
    "            ))\n",
    "        return \"\\n-----\\n\".join(docs)    \n",
    "\n",
    "class SearchPapersInput(BaseModel):\n",
    "    \"\"\"Input object to search papers with the CORE API.\"\"\"\n",
    "    query: str = Field(description=\"The query to search for on the selected archive.\")\n",
    "    max_papers: int = Field(description=\"The maximum number of papers to return. It's default to 1, but you can increase it up to 10 in case you need to perform a more comprehensive search.\", default=1, ge=1, le=10)\n",
    "\n",
    "class DecisionMakingOutput(BaseModel):\n",
    "    \"\"\"Output object of the decision making node.\"\"\"\n",
    "    requires_research: bool = Field(description=\"Whether the user query requires research or not.\")\n",
    "    answer: Optional[str] = Field(default=None, description=\"The answer to the user query. It should be None if the user query requires research, otherwise it should be a direct answer to the user query.\")\n",
    "\n",
    "class JudgeOutput(BaseModel):\n",
    "    \"\"\"Output object of the judge node.\"\"\"\n",
    "    is_good_answer: bool = Field(description=\"Whether the answer is good or not.\")\n",
    "    feedback: Optional[str] = Field(default=None, description=\"Detailed feedback about why the answer is not good. It should be None if the answer is good.\")\n",
    "\n",
    "def format_tools_description(tools: list[BaseTool]) -> str:\n",
    "    return \"\\n\\n\".join([f\"- {tool.name}: {tool.description}\\n Input arguments: {tool.args}\" for tool in tools])\n",
    "\n",
    "async def print_stream(app: CompiledStateGraph, input: str) -> Optional[BaseMessage]:\n",
    "    display(Markdown(\"## New research running\"))\n",
    "    display(Markdown(f\"### Input:\\n\\n{input}\\n\\n\"))\n",
    "    display(Markdown(\"### Stream:\\n\\n\"))\n",
    "\n",
    "    # Stream the results \n",
    "    all_messages = []\n",
    "    async for chunk in app.astream({\"messages\": [input]}, stream_mode=\"updates\"):\n",
    "        for updates in chunk.values():\n",
    "            if messages := updates.get(\"messages\"):\n",
    "                all_messages.extend(messages)\n",
    "                for message in messages:\n",
    "                    message.pretty_print()\n",
    "                    print(\"\\n\\n\")\n",
    " \n",
    "    # Return the last message if any\n",
    "    if not all_messages:\n",
    "        return None\n",
    "    return all_messages[-1]\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df709f",
   "metadata": {},
   "source": [
    "## Agent state\n",
    "This cell defines the agent state, which contains the following information:\n",
    "\n",
    "- requires_research: Whether the user query requires research or not.\n",
    "- num_feedback_requests: The number of times the LLM asked for feedback.\n",
    "- is_good_answer: Whether the LLM's final answer is good or not.\n",
    "- messages: The conversation history between the user and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "572e4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent during the paper research process.\"\"\"\n",
    "    requires_research: bool = False\n",
    "    num_feedback_requests: int = 0\n",
    "    is_good_answer: bool = False\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce25284",
   "metadata": {},
   "source": [
    "Agent tools\n",
    "This cell defines the tools available to the agent. The toolkit contains a tool to search for scientific papers using the CORE API, a tool to download a scientific paper from a given URL, and a tool to ask for human feedback.\n",
    "\n",
    "To make the paper download more robust, the tool includes a retry mechanism, similar to the one used for the CORE API, as well as a mock browser header to avoid 403 errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ddc4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"search-papers\", args_schema=SearchPapersInput)\n",
    "def search_papers(query: str, max_papers: int = 1) -> str:\n",
    "    \"\"\"Search for scientific papers using the CORE API.\n",
    "\n",
    "    Example:\n",
    "    {\"query\": \"Attention is all you need\", \"max_papers\": 1}\n",
    "\n",
    "    Returns:\n",
    "        A list of the relevant papers found with the corresponding relevant information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return CoreAPIWrapper(top_k_results=max_papers).search(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error performing paper search: {e}\"\n",
    "\n",
    "@tool(\"download-paper\")\n",
    "def download_paper(url: str) -> str:\n",
    "    \"\"\"Download a specific scientific paper from a given URL.\n",
    "\n",
    "    Example:\n",
    "    {\"url\": \"https://sample.pdf\"}\n",
    "\n",
    "    Returns:\n",
    "        The paper content.\n",
    "    \"\"\"\n",
    "    try:        \n",
    "        http = urllib3.PoolManager(\n",
    "            cert_reqs='CERT_NONE',\n",
    "        )\n",
    "        \n",
    "        # Mock browser headers to avoid 403 error\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        max_retries = 5\n",
    "        for attempt in range(max_retries):\n",
    "            response = http.request('GET', url, headers=headers)\n",
    "            if 200 <= response.status < 300:\n",
    "                pdf_file = io.BytesIO(response.data)\n",
    "                with pdfplumber.open(pdf_file) as pdf:\n",
    "                    text = \"\"\n",
    "                    for page in pdf.pages:\n",
    "                        text += page.extract_text() + \"\\n\"\n",
    "                return text\n",
    "            elif attempt < max_retries - 1:\n",
    "                time.sleep(2 ** (attempt + 2))\n",
    "            else:\n",
    "                raise Exception(f\"Got non 2xx when downloading paper: {response.status_code} {response.text}\")\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading paper: {e}\"\n",
    "\n",
    "@tool(\"ask-human-feedback\")\n",
    "def ask_human_feedback(question: str) -> str:\n",
    "    \"\"\"Ask for human feedback. You should call this tool when encountering unexpected errors.\"\"\"\n",
    "    return input(question)\n",
    "\n",
    "tools = [search_papers, download_paper, ask_human_feedback]\n",
    "tools_dict = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed7422",
   "metadata": {},
   "source": [
    "Workflow nodes\n",
    "This cell defines the nodes of the workflow. Note how the judge_node is configured to end the execution if the LLM failed to provide a good answer twice to keep latency acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMs\n",
    "base_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", # Changed model here!\n",
    "    temperature=0,\n",
    "    google_api_key=os.getenv('GOOGLE_API_KEY')\n",
    ")\n",
    "decision_making_llm = base_llm.with_structured_output(DecisionMakingOutput)\n",
    "agent_llm = base_llm.bind_tools(tools)\n",
    "judge_llm = base_llm.with_structured_output(JudgeOutput)\n",
    "\n",
    "# Decision making node\n",
    "def decision_making_node(state: AgentState):\n",
    "    \"\"\"Entry point of the workflow. Based on the user query, the model can either respond directly or perform a full research, routing the workflow to the planning node\"\"\"\n",
    "    system_prompt = SystemMessage(content=decision_making_prompt)\n",
    "    response: DecisionMakingOutput = decision_making_llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    output = {\"requires_research\": response.requires_research}\n",
    "    if response.answer:\n",
    "        output[\"messages\"] = [AIMessage(content=response.answer)]\n",
    "    return output\n",
    "\n",
    "# Task router function\n",
    "def router(state: AgentState):\n",
    "    \"\"\"Router directing the user query to the appropriate branch of the workflow.\"\"\"\n",
    "    if state[\"requires_research\"]:\n",
    "        return \"planning\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Planning node\n",
    "def planning_node(state: AgentState):\n",
    "    \"\"\"Planning node that creates a step by step plan to answer the user query.\"\"\"\n",
    "    system_prompt = SystemMessage(content=planning_prompt.format(tools=format_tools_description(tools)))\n",
    "    response = base_llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Tool call node\n",
    "def tools_node(state: AgentState):\n",
    "    \"\"\"Tool call node that executes the tools based on the plan.\"\"\"\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool_result = tools_dict[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "# Agent call node\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"Agent call node that uses the LLM with tools to answer the user query.\"\"\"\n",
    "    system_prompt = SystemMessage(content=agent_prompt)\n",
    "    response = agent_llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Should continue function\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Check if the agent should continue or end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # End execution if there are no tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Judge node\n",
    "def judge_node(state: AgentState):\n",
    "    \"\"\"Node to let the LLM judge the quality of its own final answer.\"\"\"\n",
    "    # End execution if the LLM failed to provide a good answer twice.\n",
    "    num_feedback_requests = state.get(\"num_feedback_requests\", 0)\n",
    "    if num_feedback_requests >= 2:\n",
    "        return {\"is_good_answer\": True}\n",
    "\n",
    "    system_prompt = SystemMessage(content=judge_prompt)\n",
    "    response: JudgeOutput = judge_llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    output = {\n",
    "        \"is_good_answer\": response.is_good_answer,\n",
    "        \"num_feedback_requests\": num_feedback_requests + 1\n",
    "    }\n",
    "    if response.feedback:\n",
    "        output[\"messages\"] = [AIMessage(content=response.feedback)]\n",
    "    return output\n",
    "\n",
    "# Final answer router function\n",
    "def final_answer_router(state: AgentState):\n",
    "    \"\"\"Router to end the workflow or improve the answer.\"\"\"\n",
    "    if state[\"is_good_answer\"]:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"planning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b08712",
   "metadata": {},
   "source": [
    "Workflow definition\n",
    "This cell defines the workflow using LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8632691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"decision_making\", decision_making_node)\n",
    "workflow.add_node(\"planning\", planning_node)\n",
    "workflow.add_node(\"tools\", tools_node)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"judge\", judge_node)\n",
    "\n",
    "# Set the entry point of the graph\n",
    "workflow.set_entry_point(\"decision_making\")\n",
    "\n",
    "# Add edges between nodes\n",
    "workflow.add_conditional_edges(\n",
    "    \"decision_making\",\n",
    "    router,\n",
    "    {\n",
    "        \"planning\": \"planning\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"planning\", \"agent\")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"end\": \"judge\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"judge\",\n",
    "    final_answer_router,\n",
    "    {\n",
    "        \"planning\": \"planning\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf0253",
   "metadata": {},
   "source": [
    "### Example usecase for PhD academic research\n",
    "This cell tests the workflow with several example queries. These queries are designed to evaluate the agent on the following aspects:\n",
    "\n",
    "- Completing tasks that are representative of the work a PhD researcher might need to perform.\n",
    "- Addressing more specific tasks that require researching papers within a defined timeframe.\n",
    "- Tackling tasks across multiple areas of research.\n",
    "- Critically evaluating its own responses by sourcing specific information from the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc3f76f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## New research running"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Input:\n",
       "\n",
       "Download and summarize the findings of this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11379842/pdf/11671_2024_Article_4070.pdf\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Stream:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I am sorry, but I cannot directly download and summarize the content of a PDF file from a URL. My capabilities do not include web scraping or PDF parsing.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## New research running"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Input:\n",
       "\n",
       "Can you find 8 papers on quantum machine learning?\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Stream:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is a plan to find 8 papers on quantum machine learning:\n",
      "\n",
      "1.  **Search for papers on quantum machine learning.**\n",
      "    *   **Tool:** `search-papers`\n",
      "    *   **Parameters:** `{\"query\": \"quantum machine learning\", \"max_papers\": 8}`\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "    *   **Reason:** This will directly search for papers matching the specified topic and retrieve the desired number of results.\n",
      "\n",
      "I will now execute the plan.\n",
      "Tool Calls:\n",
      "  search-papers (c7aaa903-0619-49f0-a04e-4876bef925fa)\n",
      " Call ID: c7aaa903-0619-49f0-a04e-4876bef925fa\n",
      "  Args:\n",
      "    max_papers: 8.0\n",
      "    query: quantum machine learning\n",
      "\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search-papers\n",
      "\n",
      "\"* ID: 73423988,\\n* Title: Quantum Machine Learning,\\n* Published Date: 2018-05-10T01:00:00+01:00,\\n* Authors: Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth,\\n* Abstract: Fuelled by increasing computer power and algorithmic advances, machine\\nlearning techniques have become powerful tools for finding patterns in data.\\nSince quantum systems produce counter-intuitive patterns believed not to be\\nefficiently produced by classical systems, it is reasonable to postulate that\\nquantum computers may outperform classical computers on machine learning tasks.\\nThe field of quantum machine learning explores how to devise and implement\\nconcrete quantum software that offers such advantages. Recent work has made\\nclear that the hardware and software challenges are still considerable but has\\nalso opened paths towards solutions.Comment: 24 pages, 2 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1611.09347']\\n-----\\n* ID: 129348586,\\n* Title: Machine Learning by Unitary Tensor Network of Hierarchical Tree\\n  Structure,\\n* Published Date: 2019-03-10T00:00:00+00:00,\\n* Authors: Liu, Ding and Ran, Shi-Ju and Wittek, Peter and Peng, Cheng and Garc\\u00eda, Raul Bl\\u00e1zquez and Su, Gang and Lewenstein, Maciej,\\n* Abstract: The resemblance between the methods used in quantum-many body physics and in\\nmachine learning has drawn considerable attention. In particular, tensor\\nnetworks (TNs) and deep learning architectures bear striking similarities to\\nthe extent that TNs can be used for machine learning. Previous results used\\none-dimensional TNs in image recognition, showing limited scalability and\\nflexibilities. In this work, we train two-dimensional hierarchical TNs to solve\\nimage recognition problems, using a training algorithm derived from the\\nmulti-scale entanglement renormalization ansatz. This approach introduces\\nmathematical connections among quantum many-body physics, quantum information\\ntheory, and machine learning. While keeping the TN unitary in the training\\nphase, TN states are defined, which encode classes of images into quantum\\nmany-body states. We study the quantum features of the TN states, including\\nquantum entanglement and fidelity. We find these quantities could be properties\\nthat characterize the image classes, as well as the machine learning tasks.Comment: 6 pages, 4 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1710.04833']\\n-----\\n* ID: 29557092,\\n* Title: Blind quantum machine learning,\\n* Published Date: 2015-07-26T01:00:00+01:00,\\n* Authors: Sheng, Yu-Bo and Zhou, Lan,\\n* Abstract: Blind quantum machine learning (BQML) enables a classical client with little\\nquantum technology to delegate a remote quantum machine learning to the quantum\\nserver in such a approach that the privacy data is preserved. Here we propose\\nthe first BQML protocol that the client can classify two-dimensional vectors to\\ndifferent clusters, resorting to a remote small-scale photon quantum\\ncomputation processor. During the protocol, the client is only required to\\nrotate and measure the single qubit. The protocol is secure without leaking any\\nrelevant information to the Eve. Any eavesdropper who attempts to intercept and\\ndisturb the learning process can be noticed. In principle, this protocol can be\\nused to classify high dimensional vectors and may provide a new viewpoint and\\napplication for quantum machine learning.Comment: 5 pages, 1 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1507.07195']\\n-----\\n* ID: 141534527,\\n* Title: Experimental Machine Learning of Quantum States,\\n* Published Date: 2018-06-21T01:00:00+01:00,\\n* Authors: Gao, Jun and Qiao, Lu-Feng and Jiao, Zhi-Qiang and Ma, Yue-Chi and Hu, Cheng-Qiu and Ren, Ruo-Jing and Yang, Ai-Lin and Tang, Hao and Yung, Man-Hong and Jin, Xian-Min,\\n* Abstract: Quantum information technologies provide promising applications in\\ncommunication and computation, while machine learning has become a powerful\\ntechnique for extracting meaningful structures in 'big data'. A crossover\\nbetween quantum information and machine learning represents a new\\ninterdisciplinary area stimulating progresses in both fields. Traditionally, a\\nquantum state is characterized by quantum state tomography, which is a\\nresource-consuming process when scaled up. Here we experimentally demonstrate a\\nmachine-learning approach to construct a quantum-state classifier for\\nidentifying the separability of quantum states. We show that it is possible to\\nexperimentally train an artificial neural network to efficiently learn and\\nclassify quantum states, without the need of obtaining the full information of\\nthe states. We also show how adding a hidden layer of neurons to the neural\\nnetwork can significantly boost the performance of the state classifier. These\\nresults shed new light on how classification of quantum states can be achieved\\nwith limited resources, and represent a step towards machine-learning-based\\napplications in quantum information processing.Comment: 7 pages, 6 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1712.00456']\\n-----\\n* ID: 25057605,\\n* Title: An introduction to quantum machine learning,\\n* Published Date: 2014-09-10T01:00:00+01:00,\\n* Authors: Schuld, M. and Sinayskiy, I. and Petruccione, F.,\\n* Abstract: Machine learning algorithms learn a desired input-output relation from\\nexamples in order to interpret new inputs. This is important for tasks such as\\nimage and speech recognition or strategy optimisation, with growing\\napplications in the IT industry. In the last couple of years, researchers\\ninvestigated if quantum computing can help to improve classical machine\\nlearning algorithms. Ideas range from running computationally costly algorithms\\nor their subroutines efficiently on a quantum computer to the translation of\\nstochastic methods into the language of quantum theory. This contribution gives\\na systematic overview of the emerging field of quantum machine learning. It\\npresents the approaches as well as technical details in an accessable way, and\\ndiscusses the potential of a future theory of quantum learning.Comment: to appear in Contemporary Physics; 19 pages, 10 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1409.3097']\\n-----\\n* ID: 154985574,\\n* Title: Smooth input preparation for quantum and quantum-inspired machine\\n  learning,\\n* Published Date: 2019-08-02T01:00:00+01:00,\\n* Authors: Zhao, Zhikuan and Fitzsimons, Jack K. and Rebentrost, Patrick and Dunjko, Vedran and Fitzsimons, Joseph F.,\\n* Abstract: Machine learning has recently emerged as a fruitful area for finding\\npotential quantum computational advantage. Many of the quantum enhanced machine\\nlearning algorithms critically hinge upon the ability to efficiently produce\\nstates proportional to high-dimensional data points stored in a quantum\\naccessible memory. Even given query access to exponentially many entries stored\\nin a database, the construction of which is considered a one-off overhead, it\\nhas been argued that the cost of preparing such amplitude-encoded states may\\noffset any exponential quantum advantage. Here we prove using smoothed\\nanalysis, that if the data-analysis algorithm is robust against small\\nentry-wise input perturbation, state preparation can always be achieved with\\nconstant queries. This criterion is typically satisfied in realistic machine\\nlearning applications, where input data is subjective to moderate noise. Our\\nresults are equally applicable to the recent seminal progress in\\nquantum-inspired algorithms, where specially constructed databases suffice for\\npolylogarithmic classical algorithm in low-rank cases. The consequence of our\\nfinding is that for the purpose of practical machine learning, polylogarithmic\\nprocessing time is possible under a general and flexible input model with\\nquantum algorithms or quantum-inspired classical algorithms in the low-rank\\ncases.Comment: 5 pages, 1 figur,\\n* Paper URLs: ['http://arxiv.org/abs/1804.00281']\\n-----\\n* ID: 25064237,\\n* Title: Experimental Realization of Quantum Artificial Intelligence,\\n* Published Date: 2014-10-04T01:00:00+01:00,\\n* Authors: Zhaokai, Li and Xiaomei, Liu and Nanyang, Xu and jiangfeng, Du,\\n* Abstract: Machines are possible to have some artificial intelligence like human beings\\nowing to particular algorithms or software. Such machines could learn knowledge\\nfrom what people taught them and do works according to the knowledge. In\\npractical learning cases, the data is often extremely complicated and large,\\nthus classical learning machines often need huge computational resources.\\nQuantum machine learning algorithm, on the other hand, could be exponentially\\nfaster than classical machines using quantum parallelism. Here, we demonstrate\\na quantum machine learning algorithm on a four-qubit NMR test bench to solve an\\noptical character recognition problem, also known as the handwriting\\nrecognition. The quantum machine learns standard character fonts and then\\nrecognize handwritten characters from a set with two candidates. To our best\\nknowledge, this is the first artificial intelligence realized on a quantum\\nprocessor. Due to the widespreading importance of artificial intelligence and\\nits tremendous consuming of computational resources, quantum speedup would be\\nextremely attractive against the challenges from the Big Data.Comment: 7 pages, 4 figure,\\n* Paper URLs: ['http://arxiv.org/abs/1410.1054']\\n-----\\n* ID: 200818797,\\n* Title: NetKet: A Machine Learning Toolkit for Many-Body Quantum Systems,\\n* Published Date: 2019-03-29T00:00:00+00:00,\\n* Authors: Carleo, Giuseppe and Choo, Kenny and Hofmann, Damian and Smith, James E. T. and Westerhout, Tom and Alet, Fabien and Davis, Emily J. and Efthymiou, Stavros and Glasser, Ivan and Lin, Sheng-Hsuan and Mauri, Marta and Mazzola, Guglielmo and Mendl, Christian B. and van Nieuwenburg, Evert and O'Reilly, Ossian and Th\\u00e9veniaut, Hugo and Torlai, Giacomo and Wietek, Alexander,\\n* Abstract: We introduce NetKet, a comprehensive open source framework for the study of\\nmany-body quantum systems using machine learning techniques. The framework is\\nbuilt around a general and flexible implementation of neural-network quantum\\nstates, which are used as a variational ansatz for quantum wave functions.\\nNetKet provides algorithms for several key tasks in quantum many-body physics\\nand quantum technology, namely quantum state tomography, supervised learning\\nfrom wave-function data, and ground state searches for a wide range of\\ncustomizable lattice models. Our aim is to provide a common platform for open\\nresearch and to stimulate the collaborative development of computational\\nmethods at the interface of machine learning and many-body physics,\\n* Paper URLs: ['http://arxiv.org/abs/1904.00031']\"\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are 8 papers on quantum machine learning:\n",
      "\n",
      "1.  **Title:** Quantum Machine Learning\n",
      "    *   **Authors:** Biamonte, Jacob; Wittek, Peter; Pancotti, Nicola; Rebentrost, Patrick; Wiebe, Nathan; Lloyd, Seth\n",
      "    *   **Published Date:** 2018-05-10\n",
      "    *   **Abstract:** This paper explores how to devise and implement concrete quantum software that offers advantages in machine learning tasks, postulating that quantum computers may outperform classical computers due to their ability to produce counter-intuitive patterns not efficiently produced by classical systems [1].\n",
      "\n",
      "2.  **Title:** Machine Learning by Unitary Tensor Network of Hierarchical Tree Structure\n",
      "    *   **Authors:** Liu, Ding; Ran, Shi-Ju; Wittek, Peter; Peng, Cheng; García, Raul Blázquez; Su, Gang; Lewenstein, Maciej\n",
      "    *   **Published Date:** 2019-03-10\n",
      "    *   **Abstract:** This work trains two-dimensional hierarchical tensor networks to solve image recognition problems, drawing connections between quantum many-body physics, quantum information theory, and machine learning. It also investigates quantum features like entanglement and fidelity as potential characteristics of image classes and machine learning tasks [2].\n",
      "\n",
      "3.  **Title:** Blind quantum machine learning\n",
      "    *   **Authors:** Sheng, Yu-Bo; Zhou, Lan\n",
      "    *   **Published Date:** 2015-07-26\n",
      "    *   **Abstract:** This paper proposes a blind quantum machine learning protocol that allows a classical client to delegate quantum machine learning to a remote quantum server while preserving data privacy. The protocol is secure and can be used for classifying high-dimensional vectors [3].\n",
      "\n",
      "4.  **Title:** Experimental Machine Learning of Quantum States\n",
      "    *   **Authors:** Gao, Jun; Qiao, Lu-Feng; Jiao, Zhi-Qiang; Ma, Yue-Chi; Hu, Cheng-Qiu; Ren, Ruo-Jing; Yang, Ai-Lin; Tang, Hao; Yung, Man-Hong; Jin, Xian-Min\n",
      "    *   **Published Date:** 2018-06-21\n",
      "    *   **Abstract:** This paper experimentally demonstrates a machine-learning approach to construct a quantum-state classifier for identifying the separability of quantum states, showing that an artificial neural network can efficiently learn and classify quantum states without full state information [4].\n",
      "\n",
      "5.  **Title:** An introduction to quantum machine learning\n",
      "    *   **Authors:** Schuld, M.; Sinayskiy, I.; Petruccione, F.\n",
      "    *   **Published Date:** 2014-09-10\n",
      "    *   **Abstract:** This paper provides a systematic overview of quantum machine learning, discussing approaches and technical details, and exploring the potential of a future theory of quantum learning [5].\n",
      "\n",
      "6.  **Title:** Smooth input preparation for quantum and quantum-inspired machine learning\n",
      "    *   **Authors:** Zhao, Zhikuan; Fitzsimons, Jack K.; Rebentrost, Patrick; Dunjko, Vedran; Fitzsimons, Joseph F.\n",
      "    *   **Published Date:** 2019-08-02\n",
      "    *   **Abstract:** This paper proves that if a data-analysis algorithm is robust against small input perturbations, state preparation for quantum and quantum-inspired machine learning can be achieved with constant queries, which is typically satisfied in realistic machine learning applications [6].\n",
      "\n",
      "7.  **Title:** Experimental Realization of Quantum Artificial Intelligence\n",
      "    *   **Authors:** Zhaokai, Li; Xiaomei, Liu; Nanyang, Xu; jiangfeng, Du\n",
      "    *   **Published Date:** 2014-10-04\n",
      "    *   **Abstract:** This paper demonstrates a quantum machine learning algorithm on a four-qubit NMR test bench to solve an optical character recognition problem, marking the first artificial intelligence realized on a quantum processor [7].\n",
      "\n",
      "8.  **Title:** NetKet: A Machine Learning Toolkit for Many-Body Quantum Systems\n",
      "    *   **Authors:** Carleo, Giuseppe; Choo, Kenny; Hofmann, Damian; Smith, James E. T.; Westerhout, Tom; Alet, Fabien; Davis, Emily J.; Efthymiou, Stavros; Glasser, Ivan; Lin, Sheng-Hsuan; Mauri, Marta; Mazzola, Guglielmo; Mendl, Christian B.; van Nieuwenburg, Evert; O'Reilly, Ossian; Théveniaut, Hugo; Torlai, Giacomo; Wietek, Alexander\n",
      "    *   **Published Date:** 2019-03-29\n",
      "    *   **Abstract:** This paper introduces NetKet, an open-source framework for studying many-body quantum systems using machine learning techniques, built around a flexible implementation of neural-network quantum states [8].\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## New research running"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Input:\n",
       "\n",
       "Find recent papers (2023-2024) about CRISPR applications in treating genetic disorders, \n",
       "    focusing on clinical trials and safety protocols\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Stream:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is a step-by-step plan to find recent papers (2023-2024) about CRISPR applications in treating genetic disorders, focusing on clinical trials and safety protocols:\n",
      "\n",
      "1.  **Search for recent papers on CRISPR applications in genetic disorders, clinical trials, and safety protocols.**\n",
      "    *   **Tool:** `search-papers`\n",
      "    *   **Parameters:**\n",
      "        *   `query`: \"CRISPR genetic disorders clinical trials safety protocols 2023 OR 2024\"\n",
      "        *   `max_papers`: 5 (This number can be increased up to 10 if more results are needed after reviewing the initial set.)\n",
      "\n",
      "2.  **Review the search results.**\n",
      "    *   Examine the titles and abstracts of the papers returned from the search to identify the most relevant ones that specifically discuss clinical trials and safety protocols for CRISPR in genetic disorders.\n",
      "\n",
      "3.  **Download the full content of the most relevant papers.**\n",
      "    *   For each paper identified in Step 2, use the `download-paper` tool.\n",
      "    *   **Tool:** `download-paper`\n",
      "    *   **Parameters:**\n",
      "        *   `url`: (The URL of the paper obtained from the `search-papers` output.)\n",
      "    *   *Repeat this step for each relevant paper.*\n",
      "\n",
      "4.  **Analyze the downloaded papers for information on clinical trials and safety protocols.**\n",
      "    *   Read through the full content of the downloaded papers to extract detailed information regarding ongoing or completed clinical trials, their methodologies, outcomes, and specific safety protocols or considerations discussed.\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "5.  **Synthesize the findings.**\n",
      "    *   Compile the gathered information into a concise summary, highlighting key advancements, challenges, and future directions in CRISPR applications for genetic disorders, with a particular focus on clinical trials and safety.\n",
      "\n",
      "I will now proceed with step 1.\n",
      "Tool Calls:\n",
      "  search-papers (3679f3ee-213b-4721-811b-32b83424a025)\n",
      " Call ID: 3679f3ee-213b-4721-811b-32b83424a025\n",
      "  Args:\n",
      "    max_papers: 5.0\n",
      "    query: CRISPR AND genetic disorders AND clinical trials AND safety protocols AND (yearPublished:2023 OR yearPublished:2024)\n",
      "\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search-papers\n",
      "\n",
      "\"* ID: 592787179,\\n* Title: Progress and harmonization of gene editing to treat human diseases: Proceeding of COST Action CA21113 GenE-HumDi,\\n* Published Date: 2023-01-01T00:00:00+00:00,\\n* Authors: Cavazza A. and Hendel A. and Bak R. O. and Rio P. and Guell M. and Lainscek D. and Arechavala-Gomeza V. and Peng L. and Hapil F. Z. and Harvey J. and Ortega F. G. and Gonzalez-Martinez C. and Lederer C. W. and Mikkelsen K. and Gasiunas G. and Kalter N. and Goncalves M. A. F. V. and Petersen J. and Garanto A. and Montoliu L. and Maresca M. and Seemann S. E. and Gorodkin J. and Mazini L. and Sanchez R. and Rodriguez-Madoz J. R. and Maldonado-Perez N. and Laura T. and Schmueck-Henneresse M. and Maccalli C. and Grunewald J. and Carmona G. and Kachamakova-Trojanowska N. and Miccio A. and Martin F. and Turchiano G. and Cathomen T. and Luo Y. and Tsai S. Q. and Benabdellah K.,\\n* Abstract: The European Cooperation in Science and Technology (COST) is an intergovernmental organization dedicated to funding and coordinating scientific and technological research in Europe, fostering collaboration among researchers and institutions across countries. Recently, COST Action funded the \\u201cGenome Editing to treat Human Diseases\\u201d (GenE-HumDi) network, uniting various stakeholders such as pharmaceutical companies, academic institutions, regulatory agencies, biotech firms, and patient advocacy groups. GenE-HumDi's primary objective is to expedite the application of genome editing for therapeutic purposes in treating human diseases. To achieve this goal, GenE-HumDi is organized in several working groups, each focusing on specific aspects. These groups aim to enhance genome editing technologies, assess delivery systems, address safety concerns, promote clinical translation, and develop regulatory guidelines. The network seeks to establish standard procedures and guidelines for these areas to standardize scientific practices and facilitate knowledge sharing. Furthermore, GenE-HumDi aims to communicate its findings to the public in accessible yet rigorous language, emphasizing genome editing's potential to revolutionize the treatment of many human diseases. The inaugural GenE-HumDi meeting, held in Granada, Spain, in March 2023, featured presentations from experts in the field, discussing recent breakthroughs in delivery methods, safety measures, clinical translation, and regulatory aspects related to gene editing,\\n* Paper URLs: ['https://iris.unimore.it/bitstream/11380/1327197/2/1-s2.0-S2162253123002846-main.pdf']\\n-----\\n* ID: 614769142,\\n* Title: iPSC-derived liver organoids and inherited bleeding disorders : potential and future perspectives,\\n* Published Date: 2024-08-05T15:30:06+01:00,\\n* Authors: Roman, Giacomo and Stavik, Benedicte and Lauritzen, Knut H. and Sandset, Per Morten and Harrison, Sean P. and Sullivan, Gareth J. and Chollet, Maria Eugenia,\\n* Abstract: Funding: This work was made possible with funding from the Norwegian Research Council (325869) and the South-Eastern Norway Regional Health Authority (2019071).The bleeding phenotype of hereditary coagulation disorders is caused by the low or undetectable activity of the proteins involved in hemostasis, due to a broad spectrum of genetic alterations. Most of the affected coagulation factors are produced in the liver. Therefore, two-dimensional (2D) cultures of primary human hepatocytes and recombinant overexpression of the factors in non-human cell lines have been primarily used to mimic disease pathogenesis and as a model for innovative therapeutic strategies. However, neither human nor animal cells fully represent the hepatocellular biology and do not harbor the exact genetic background of the patient. As a result, the inability of the current in vitro models in recapitulating the in vivo situation has limited the studies of these inherited coagulation disorders. Induced Pluripotent Stem Cell (iPSC) technology offers a possible solution to overcome these limitations by reprogramming patient somatic cells into an embryonic-like pluripotent state, thus giving the possibility of generating an unlimited number of liver cells needed for modeling or therapeutic purposes. By combining this potential and the recent advances in the Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)/Cas9 technology, it allows for the generation of autologous and gene corrected liver cells in the form of three-dimensional (3D) liver organoids. The organoids recapitulate cellular composition and organization of the liver, providing a more physiological model to study the biology of coagulation proteins and modeling hereditary coagulation disorders. This advanced methodology can pave the way for the development of cell-based therapeutic approaches to treat inherited coagulation disorders. In this review we will explore the use of liver organoids as a state-of-the-art methodology for modeling coagulation factors disorders and the possibilities of using organoid technology to treat the disease.Peer reviewe,\\n* Paper URLs: ['https://research-repository.st-andrews.ac.uk/bitstream/10023/30326/1/Roman-iPSC-derived-liver-organoids-FPHYS-14-1094249-CCBY.pdf']\\n-----\\n* ID: 596247487,\\n* Title: Emerging Therapies in Retinal Diseases: From Gene Therapy to Stem Cell Interventions,\\n* Published Date: 2023-09-01T01:00:00+01:00,\\n* Authors: Renuks Sarwate, Rohit Kundap , Girish Arun Gadre, Prajakta Patil, D. B. Shirke,,\\n* Abstract: Retinal disorders pose a serious threat to eye health as they frequently result in blindness and reduced vision. There is hope that the treatment of many illnesses will be revolutionised by emerging medicines, especially gene therapy and stem cell approaches. This study explores the current state of these innovative therapies and how they could affect retinal disorders. By replacing or repairing damaged genes, gene therapy, which uses precise genetic modification, shows promise in treating hereditary retinal problems. Clinical trials have yielded promising results, including improvements in visual function and optimism for patients with illnesses such as choroideremia and Leber congenital amaurosis. Regenerative approaches are provided by stem cell therapies, which restore damaged retinal tissues. Numerous stem cell varieties, including as embryonic and induced pluripotent stem cells, show promise in preclinical research and early-stage clinical trials, suggesting that cell replacement techniques may be a viable means of recovering vision. On the other hand, effective delivery, long-term safety, and ethical issues provide obstacles on the path to clinical application. To fully realise the transformational potential of these medicines, it is imperative to address these obstacles. There is potential for improved visual outcomes, targeted therapies, and personalised care as gene therapy and stem cell interventions advance. These developments highlight the promising future of treating retinal illnesses,\\n* Paper URLs: ['https://ijritcc.org/index.php/ijritcc/article/download/9421/7238']\\n-----\\n* ID: 643778551,\\n* Title: Challenges and Considerations of Preclinical Development for iPSC-Based Myogenic Cell Therapy,\\n* Published Date: 2024-03-29T07:00:00+00:00,\\n* Authors: Sun, Congshan and Serra, Carlo and Kalicharan, Brianna Harley and Harding, Jeffrey and Rao, Mahendra,\\n* Abstract: Cell therapies derived from induced pluripotent stem cells (iPSCs) offer a promising avenue in the field of regenerative medicine due to iPSCs\\\\u27 expandability, immune compatibility, and pluripotent potential. An increasing number of preclinical and clinical trials have been carried out, exploring the application of iPSC-based therapies for challenging diseases, such as muscular dystrophies. The unique syncytial nature of skeletal muscle allows stem/progenitor cells to integrate, forming new myonuclei and restoring the expression of genes affected by myopathies. This characteristic makes genome-editing techniques especially attractive in these therapies. With genetic modification and iPSC lineage specification methodologies, immune-compatible healthy iPSC-derived muscle cells can be manufactured to reverse the progression of muscle diseases or facilitate tissue regeneration. Despite this exciting advancement, much of the development of iPSC-based therapies for muscle diseases and tissue regeneration is limited to academic settings, with no successful clinical translation reported. The unknown differentiation process in vivo, potential tumorigenicity, and epigenetic abnormality of transplanted cells are preventing their clinical application. In this review, we give an overview on preclinical development of iPSC-derived myogenic cell transplantation therapies including processes related to iPSC-derived myogenic cells such as differentiation, scaling-up, delivery, and cGMP compliance. And we discuss the potential challenges of each step of clinical translation. Additionally, preclinical model systems for testing myogenic cells intended for clinical applications are described,\\n* Paper URLs: ['https://digitalcommons.library.tmc.edu/cgi/viewcontent.cgi?article=3453&context=baylor_docs']\\n-----\\n* ID: 588290687,\\n* Title: Investigating the Potential of a Cell-Based Gene Editing Therapy for Inherited Metabolic Liver Disease,\\n* Published Date: 2023-08-01T08:00:00+01:00,\\n* Authors: Ates, Ilayda,\\n* Abstract: Inherited metabolic diseases (IMDs) affecting the liver are relatively rare but collectively have a prevalence of 1 in 800 live births. These diseases result from autosomal recessive single-gene mutations, leading to organ dysfunction and potentially fatal consequences if left untreated. One potential therapeutic strategy for IMDs of the liver involves using CRISPR-Cas9-induced loss of function mutations. However, translating this approach into the clinic is limited by the need for safe and effective CRISPR delivery methods. Adeno-associated viral vectors (AAVs), commonly used for CRISPR delivery, are associated with significant safety and efficacy concerns, including risks for immunogenicity, off-target mutagenesis, and genotoxicity due to persistent Cas9 expression. Therefore, alternative delivery approaches are needed. In this study, we explore the safety and efficacy of electroporation as an alternative to viral delivery methods for ex vivo gene editing therapy for IMDs of the liver. Our strategy involves isolating hepatocytes from the resected liver of a patient, delivering CRISPR components into the hepatocytes via electroporation ex vivo, and subsequently transplanting the edited hepatocytes back into the patient\\\\u27s liver to replace the native hepatocytes with healthy gene-edited ones. Compared to systemic delivery, this approach offers advantages such as cell-specific editing, the potential to screen for off-target effects, and the opportunity to expand or cryopreserve gene-edited hepatocytes for transplantation when needed. The success of a cell-based therapy will require the edited hepatocytes to engraft and replace approximately 5-10% of the liver mass and persist for the patient\\\\u27s lifetime. iii We develop technical protocols to advance a cell-based therapeutic approach. First, we optimize hepatocyte isolation protocols to achieve high viability in freshly isolated primary hepatocytes for downstream delivery. Second, we established a mouse model for primary hepatocyte isolation and transplantation. After that, we show a successful cell therapy approach to reprogram metabolic pathways by electroporating CRISPR-Cas9 mRNA and RNPs to disrupt the gene encoding 4-hydroxyphenylpyruvate dioxygenase (Hpd) in primary hepatocytes ex vivo, followed by transplantation to treat a mouse model of hereditary tyrosinemia type 1 (HT1). Third, to assess the broader applicability of our strategy, we explore a novel cell-based gene editing approach in a mouse model of familial hypercholesterolemia. Specifically, we demonstrate clonal expansion and liver repopulation by gene-edited hepatocytes after transplantation by transient administration of acetaminophen. This study aims to provide valuable insights into the efficacy and safety of electroporation as a nonviral delivery approach for cell-based gene editing therapies for liver disease. These advancements can be applied to many inherited metabolic liver disorders and are a step toward autologous cell therapy in the liver,\\n* Paper URLs: ['https://tigerprints.clemson.edu/cgi/viewcontent.cgi?article=4432&context=all_dissertations']\"\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current output only provides a list of papers found. It does not synthesize the information from these papers regarding CRISPR applications in treating genetic disorders, focusing on clinical trials and safety protocols, which was the core of the user's request. The answer needs to analyze the content of the papers and provide a summary of the findings related to clinical trials and safety protocols.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\proto\\marshal\\rules\\enums.py:37: UserWarning: Unrecognized FinishReason enum value: 12\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m outputs = []\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m test_input \u001b[38;5;129;01min\u001b[39;00m test_inputs:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     final_answer = \u001b[38;5;28;01mawait\u001b[39;00m print_stream(app, test_input)\n\u001b[32m     17\u001b[39m     outputs.append(final_answer.content)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mprint_stream\u001b[39m\u001b[34m(app, input)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Stream the results \u001b[39;00m\n\u001b[32m     71\u001b[39m all_messages = []\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m app.astream({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28minput\u001b[39m]}, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m updates \u001b[38;5;129;01min\u001b[39;00m chunk.values():\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m messages := updates.get(\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2934\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2932\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2933\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2934\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2935\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2936\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2937\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2938\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2939\u001b[39m ):\n\u001b[32m   2940\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2941\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2942\u001b[39m         stream_mode,\n\u001b[32m   2943\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2946\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2947\u001b[39m     ):\n\u001b[32m   2948\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:295\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    293\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    296\u001b[39m         t,\n\u001b[32m    297\u001b[39m         retry_policy,\n\u001b[32m    298\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    299\u001b[39m         configurable={\n\u001b[32m    300\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    301\u001b[39m                 _acall,\n\u001b[32m    302\u001b[39m                 weakref.ref(t),\n\u001b[32m    303\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    304\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    305\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    306\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    307\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    308\u001b[39m                 loop=loop,\n\u001b[32m    309\u001b[39m             ),\n\u001b[32m    310\u001b[39m         },\n\u001b[32m    311\u001b[39m     )\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:695\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    693\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    696\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:463\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:616\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    617\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    618\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[..., T]\u001b[39m\u001b[33m\"\u001b[39m, partial(copy_context().run, wrapper)),\n\u001b[32m    619\u001b[39m     )\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:607\u001b[39m, in \u001b[36mrun_in_executor.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m() -> T:\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    609\u001b[39m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mplanning_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Planning node that creates a step by step plan to answer the user query.\"\"\"\u001b[39;00m\n\u001b[32m     32\u001b[39m system_prompt = SystemMessage(content=planning_prompt.format(tools=format_tools_description(tools)))\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m response = \u001b[43mbase_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1326\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1323\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1324\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1439\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1421\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1422\u001b[39m     messages,\n\u001b[32m   1423\u001b[39m     stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1431\u001b[39m     **kwargs,\n\u001b[32m   1432\u001b[39m )\n\u001b[32m   1433\u001b[39m response: GenerateContentResponse = _chat_with_retry(\n\u001b[32m   1434\u001b[39m     request=request,\n\u001b[32m   1435\u001b[39m     **kwargs,\n\u001b[32m   1436\u001b[39m     generation_method=\u001b[38;5;28mself\u001b[39m.client.generate_content,\n\u001b[32m   1437\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m.default_metadata,\n\u001b[32m   1438\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_response_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:758\u001b[39m, in \u001b[36m_response_to_result\u001b[39m\u001b[34m(response, stream, prev_usage)\u001b[39m\n\u001b[32m    756\u001b[39m generation_info = {}\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m candidate.finish_reason:\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     generation_info[\u001b[33m\"\u001b[39m\u001b[33mfinish_reason\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcandidate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish_reason\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    759\u001b[39m     \u001b[38;5;66;03m# Add model_name in last chunk\u001b[39;00m\n\u001b[32m    760\u001b[39m     generation_info[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m] = response.model_version\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'name'",
      "During task with name 'planning' and id '413718ca-be26-78f8-e54c-131f3e25fbc8'"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"Download and summarize the findings of this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11379842/pdf/11671_2024_Article_4070.pdf\",\n",
    "\n",
    "    \"Can you find 8 papers on quantum machine learning?\",\n",
    "\n",
    "    \"\"\"Find recent papers (2023-2024) about CRISPR applications in treating genetic disorders, \n",
    "    focusing on clinical trials and safety protocols\"\"\",\n",
    "\n",
    "    \"\"\"Find and analyze papers from 2023-2024 about the application of transformer architectures in protein folding prediction, \n",
    "    specifically looking for novel architectural modifications with experimental validation.\"\"\"\n",
    "]\n",
    "\n",
    "# Run tests and store the results for later visualisation\n",
    "outputs = []\n",
    "for test_input in test_inputs:\n",
    "    final_answer = await print_stream(app, test_input)\n",
    "    outputs.append(final_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2979c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Input:\n",
       "\n",
       "Download and summarize the findings of this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11379842/pdf/11671_2024_Article_4070.pdf\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Output:\n",
       "\n",
       "I am sorry, but I cannot directly download and summarize the content of a PDF file from a URL. My capabilities do not include web scraping or PDF parsing.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Input:\n",
       "\n",
       "Can you find 8 papers on quantum machine learning?\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Output:\n",
       "\n",
       "Here are 8 papers on quantum machine learning:\n",
       "\n",
       "1.  **Title:** Quantum Machine Learning\n",
       "    *   **Authors:** Biamonte, Jacob; Wittek, Peter; Pancotti, Nicola; Rebentrost, Patrick; Wiebe, Nathan; Lloyd, Seth\n",
       "    *   **Published Date:** 2018-05-10\n",
       "    *   **Abstract:** This paper explores how to devise and implement concrete quantum software that offers advantages in machine learning tasks, postulating that quantum computers may outperform classical computers due to their ability to produce counter-intuitive patterns not efficiently produced by classical systems [1].\n",
       "\n",
       "2.  **Title:** Machine Learning by Unitary Tensor Network of Hierarchical Tree Structure\n",
       "    *   **Authors:** Liu, Ding; Ran, Shi-Ju; Wittek, Peter; Peng, Cheng; García, Raul Blázquez; Su, Gang; Lewenstein, Maciej\n",
       "    *   **Published Date:** 2019-03-10\n",
       "    *   **Abstract:** This work trains two-dimensional hierarchical tensor networks to solve image recognition problems, drawing connections between quantum many-body physics, quantum information theory, and machine learning. It also investigates quantum features like entanglement and fidelity as potential characteristics of image classes and machine learning tasks [2].\n",
       "\n",
       "3.  **Title:** Blind quantum machine learning\n",
       "    *   **Authors:** Sheng, Yu-Bo; Zhou, Lan\n",
       "    *   **Published Date:** 2015-07-26\n",
       "    *   **Abstract:** This paper proposes a blind quantum machine learning protocol that allows a classical client to delegate quantum machine learning to a remote quantum server while preserving data privacy. The protocol is secure and can be used for classifying high-dimensional vectors [3].\n",
       "\n",
       "4.  **Title:** Experimental Machine Learning of Quantum States\n",
       "    *   **Authors:** Gao, Jun; Qiao, Lu-Feng; Jiao, Zhi-Qiang; Ma, Yue-Chi; Hu, Cheng-Qiu; Ren, Ruo-Jing; Yang, Ai-Lin; Tang, Hao; Yung, Man-Hong; Jin, Xian-Min\n",
       "    *   **Published Date:** 2018-06-21\n",
       "    *   **Abstract:** This paper experimentally demonstrates a machine-learning approach to construct a quantum-state classifier for identifying the separability of quantum states, showing that an artificial neural network can efficiently learn and classify quantum states without full state information [4].\n",
       "\n",
       "5.  **Title:** An introduction to quantum machine learning\n",
       "    *   **Authors:** Schuld, M.; Sinayskiy, I.; Petruccione, F.\n",
       "    *   **Published Date:** 2014-09-10\n",
       "    *   **Abstract:** This paper provides a systematic overview of quantum machine learning, discussing approaches and technical details, and exploring the potential of a future theory of quantum learning [5].\n",
       "\n",
       "6.  **Title:** Smooth input preparation for quantum and quantum-inspired machine learning\n",
       "    *   **Authors:** Zhao, Zhikuan; Fitzsimons, Jack K.; Rebentrost, Patrick; Dunjko, Vedran; Fitzsimons, Joseph F.\n",
       "    *   **Published Date:** 2019-08-02\n",
       "    *   **Abstract:** This paper proves that if a data-analysis algorithm is robust against small input perturbations, state preparation for quantum and quantum-inspired machine learning can be achieved with constant queries, which is typically satisfied in realistic machine learning applications [6].\n",
       "\n",
       "7.  **Title:** Experimental Realization of Quantum Artificial Intelligence\n",
       "    *   **Authors:** Zhaokai, Li; Xiaomei, Liu; Nanyang, Xu; jiangfeng, Du\n",
       "    *   **Published Date:** 2014-10-04\n",
       "    *   **Abstract:** This paper demonstrates a quantum machine learning algorithm on a four-qubit NMR test bench to solve an optical character recognition problem, marking the first artificial intelligence realized on a quantum processor [7].\n",
       "\n",
       "8.  **Title:** NetKet: A Machine Learning Toolkit for Many-Body Quantum Systems\n",
       "    *   **Authors:** Carleo, Giuseppe; Choo, Kenny; Hofmann, Damian; Smith, James E. T.; Westerhout, Tom; Alet, Fabien; Davis, Emily J.; Efthymiou, Stavros; Glasser, Ivan; Lin, Sheng-Hsuan; Mauri, Marta; Mazzola, Guglielmo; Mendl, Christian B.; van Nieuwenburg, Evert; O'Reilly, Ossian; Théveniaut, Hugo; Torlai, Giacomo; Wietek, Alexander\n",
       "    *   **Published Date:** 2019-03-29\n",
       "    *   **Abstract:** This paper introduces NetKet, an open-source framework for studying many-body quantum systems using machine learning techniques, built around a flexible implementation of neural-network quantum states [8].\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for input, output in zip(test_inputs, outputs):\n",
    "    display(Markdown(f\"## Input:\\n\\n{input}\\n\\n\"))\n",
    "    display(Markdown(f\"## Output:\\n\\n{output}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737548f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e297e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
