{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Q&A Bot Demo\n",
    "This notebook demonstrates how to use the enhanced Q&A bot with conversation history and persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "First, let's install the required packages if they're not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Enhanced Q&A Bot\n",
    "Let's import the `QABot` class from our enhanced implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from enhanced_qa_bot import QABot\n",
    "\n",
    "# Load environment variables (make sure you have a .env file with GOOGLE_API_KEY)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Q&A Bot\n",
    "Create a new instance of the QABot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the bot\n",
    "bot = QABot(\n",
    "    model_name=\"gemini-1.5-flash\",  # You can change the model if needed\n",
    "    temperature=0.7  # Adjust for more creative (higher) or focused (lower) responses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "Let's have a simple conversation with the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation with a unique session ID\n",
    "session_id = \"demo_session_001\"\n",
    "\n",
    "# First message\n",
    "response = bot.get_response(\"Hello! How are you today?\", session_id)\n",
    "print(f\\\"User: Hello! How are you today?\\nAI: {response}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing the Conversation\n",
    "The bot remembers the conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a follow-up question\n",
    "response = bot.get_response(\"What was my first message to you?\", session_id)\n",
    "print(f\\\"User: What was my first message to you?\\nAI: {response}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Conversation History\n",
    "You can retrieve the full conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the conversation history\n",
    "history = bot.get_conversation_history(session_id)\n",
    "print(\"\\nConversation History:\")\n",
    "for i, msg in enumerate(history, 1):\n",
    "    print(f\\\"{i}. {msg['role'].upper()}: {msg['content']}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Conversation History\n",
    "You can clear the conversation history when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the conversation\n",
    "bot.clear_conversation(session_id)\n",
    "print(\"Conversation history has been cleared.\")\n",
    "\n",
    "# Verify it's cleared\n",
    "history = bot.get_conversation_history(session_id)\n",
    "print(f\\\"History length after clearing: {len(history)}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Sessions\n",
    "The bot can handle multiple independent conversations using different session IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First session\n",
    "session1 = \"weather_session\"\n",
    "response = bot.get_response(\"What's the weather like today?\", session1)\n",
    "print(f\\\"Session 1 - User: What's the weather like today?\\nAI: {response}\\\")\n",
    "\n",
    "# Second session (independent of the first)\n",
    "session2 = \"math_session\"\n",
    "response = bot.get_response(\"What's 2 + 2?\", session2)\n",
    "print(f\\\"\\nSession 2 - User: What's 2 + 2?\\nAI: {response}\\\")\n",
    "\n",
    "# Each session maintains its own history\n",
    "print(\"\\nSession 1 History:\")\n",
    "for msg in bot.get_conversation_history(session1):\n",
    "    print(f\\\"{msg['role'].upper()}: {msg['content']}\\\")\n",
    "\n",
    "print(\"\\nSession 2 History:\")\n",
    "for msg in bot.get_conversation_history(session2):\n",
    "    print(f\\\"{msg['role'].upper()}: {msg['content']}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence Across Sessions\n",
    "The conversation history is automatically saved to disk and will persist even if you restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To test persistence, restart the kernel and run the cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After restarting the kernel, run this to verify persistence\n",
    "from enhanced_qa_bot import QABot\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "bot = QABot()\n",
    "\n",
    "# Check if our previous sessions are still there\n",
    "print(\"Session 1 History (should be empty if you cleared it earlier):\")\n",
    "for msg in bot.get_conversation_history(\"demo_session_001\"):\n",
    "    print(f\\\"{msg['role'].upper()}: {msg['content']}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "You can also customize the bot's behavior by modifying the system prompt or other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a bot with a custom system prompt\n",
    "custom_bot = QABot(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    temperature=0.9,  # More creative responses\n",
    "    system_prompt=\\\"You are a helpful assistant that speaks like a pirate. Always include 'Arrr!' in your responses.\\\"\n",
    ")\n",
    "\n",
    "response = custom_bot.get_response(\"Hello! How are you?\", \"pirate_session\")\n",
    "print(f\\\"User: Hello! How are you?\\nAI: {response}\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
