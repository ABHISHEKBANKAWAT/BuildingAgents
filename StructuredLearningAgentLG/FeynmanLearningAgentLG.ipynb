{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f368e6e6",
   "metadata": {},
   "source": [
    "## Structured Learning Agent using LangGraph\n",
    "In this notebook, we will build a structured learning agent using LangGraph. The system will guide learners through a structured learning process of defined but customizable checkpoints. Verifying understanding at each step and providing feynman-style teaching when needed.\n",
    "\n",
    "## Motivation\n",
    "- Access to personalized 1:1 tutoring is expensive and not accessible to everyone.\n",
    "- Provide individualized learning experience to each learner and feedback 24/7.\n",
    "- Use own notes and web-retrieved content as context.\n",
    "- Offer patient, simple explanations of complex topics.\n",
    "\n",
    "## Key Components\n",
    "1. Learning State Graph: Orchestrates the sequential learning workflow.\n",
    "2. Checkpoint System: Defines structured learning milestones.\n",
    "3. Web Search Integration: Dynamically retrives relevant learning materials.\n",
    "4. Context Processing: Chunks and process learning materials.\n",
    "5. Question Generation: Creates checkpoint-specific verification questions.\n",
    "6. Understanding Verification: Evaluates learner comprehension with a clear threshold.\n",
    "7. Feynman-style Teaching: Provides patient, simple explanations of complex topics.\n",
    "\n",
    "## Method\n",
    "The system follows a structured learning cycle.\n",
    "1. Checkpoint Definition\n",
    "* Generate sequential learning milestones with clear success criteria.\n",
    "\n",
    "2. Context Building\n",
    "* Processes student-provided materials or retrieves relevant web content.\n",
    "3. Context Validation\n",
    "* Validates context based on checkpoint criteria.\n",
    "* Performs additional web searches if context doesn't meet criteria.\n",
    "4. Embedding Storage\n",
    "* Stores embeddings for retrieving only relevant chunks during verification.\n",
    "5. Understanding Verification\n",
    "* Generates checkpoint-specific questions.\n",
    "* Evaluates learner's answers against correct answers.\n",
    "* Provides clear feedback on understanding level.\n",
    "6. Progressive Learning\n",
    "* Advances to the next checkpoint when understanding is verified.\n",
    "* Provides Feynman-style teaching when needed.\n",
    "\n",
    "### Conclusion\n",
    "This structured learning agent provides a personalized, 24/7 learning experience. It can be easily extended to include additional features such as progress tracking, personalized recommendations, and more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cd3ad",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "#!pip install langchain-community langchain-openai langgraph pydantic python-dotenv semantic-chunkers semantic-router tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21583f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import operator\n",
    "import uuid\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import OpenAIEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f75768",
   "metadata": {},
   "source": [
    "Setup\n",
    "This agent is implemented using OpenAI's models, but can be used also with self-hosted LLM and embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a8a582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK BANKAWAT\\AppData\\Local\\Temp\\ipykernel_23712\\406296422.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1213a",
   "metadata": {},
   "source": [
    "## Data Models Definition\n",
    "We will define data structures for our adaptive learning system using pydantic models. These models type safety and provide clear structure for:\n",
    "* Learning goals and objectives\n",
    "* Checkpoint definitions and tracking\n",
    "* Search Queries for dynamic content.\n",
    "* Verification of learning progres.\n",
    "* Feynman teaching output format.\n",
    "* Question generation.\n",
    "\n",
    "Each model is designed to capture specific aspects of the learning process while maintaining type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c601b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Goals(BaseModel):\n",
    "    \"\"\" Structure for defining learning goals.\"\"\"\n",
    "    goals: str = Field(None, description=\"Learning goals\")\n",
    "\n",
    "class LearningCheckpoint(BaseModel):\n",
    "    \"\"\" Structure for a single checkpoint \"\"\"\n",
    "    description: str = Field(..., description=\"Main checkpoint description\")\n",
    "    criteria: List[str] = Field(...,description=\"List of success criteria\")\n",
    "    verification: str = Field(..., description=\"How to verify this checkpoint\")\n",
    "\n",
    "class Checkpoints(BaseModel):\n",
    "    \"\"\" Main checkpoints container with index tracking \"\"\"\n",
    "    checkpoints: List[LearningCheckpoint] = Field(\n",
    "        ...,\n",
    "        description=\"List of checkpoints covering foundation, applicationm and mastery levels\"\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\" Structure for search query collection\"\"\"\n",
    "    search_queries: list = Field(None, description=\"Search queries for retrievel.\")\n",
    "\n",
    "class LearningVerification(BaseModel):\n",
    "    \"\"\"Structure for verification results\"\"\"\n",
    "    understanding_level: float = Field(...,ge=0, le=1)\n",
    "    feedback: str\n",
    "    suggestions: List[str]\n",
    "    context_alignment:bool\n",
    "\n",
    "class FeynmanTeaching(BaseModel):\n",
    "    \"\"\" Structure for feynman teaching Method \"\"\"\n",
    "    simplified_explanation: str\n",
    "    KeyConcepts: List[str]\n",
    "    analogies: List[str]\n",
    "    \n",
    "class QuestionOutput(BaseModel):\n",
    "    \"\"\" Structure for question output \"\"\"\n",
    "    questions: str\n",
    "\n",
    "class InContext(BaseModel):\n",
    "    \"\"\" Structure for context verification \"\"\"\n",
    "    is_in_context: str = Field(..., description=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb58190",
   "metadata": {},
   "source": [
    "## Learning State Definition\n",
    "* The Learning topic and goals\n",
    "* Context and search results\n",
    "* Current progress through checkpoints\n",
    "* Verification results and teaching outputs\n",
    "* Current question-answer pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fe243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningState(BaseModel):\n",
    "    topic: str\n",
    "    goals: List[str]\n",
    "    context: str\n",
    "    context_chunks: Annotated[list, operator.add]\n",
    "    context_key: str\n",
    "    search_queries: SearchQuery\n",
    "    checkpoints: Checkpoints\n",
    "    verifications: LearningVerification\n",
    "    teachings: FeynmanTeaching\n",
    "    current_checkpoint: int\n",
    "    current_question: QuestionOutput\n",
    "    current_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d8a5c",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "The system uses three utility functions:\n",
    "1. extract_content_from_chunks: Processes and combines text chunks into coherent content.\n",
    "2. Format_checkpoints_as_message: Converts checkpoint data into prompt format\n",
    "3. generate_checkpoint_message: Creates formatted message for context retrievel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_chunks(chunks):\n",
    "    \"\"\"Extract and combine content from chunks with splits attribute.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk objects that may contain splits attribute\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all chunks joined with newlines\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'splits') and chunk.splits:\n",
    "            chunk_content = ' '.join(chunk.splits)\n",
    "            content.append(chunk_content)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "def format_checkpoints_as_message(checkpoints: Checkpoints) -> str:\n",
    "    \"\"\"Convert Checkpoints object to a formatted string for the message.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints (Checkpoints): Checkpoints object containing learning checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing numbered checkpoints with descriptions and criteria\n",
    "    \"\"\"\n",
    "    message = \"Here are the learning checkpoints:\\n\\n\"\n",
    "    for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "        message += f\"Checkpoint {i}:\\n\"\n",
    "        message += f\"Description: {checkpoint.description}\\n\"\n",
    "        message += \"Success Criteria:\\n\"\n",
    "        for criterion in checkpoint.criteria:\n",
    "            message += f\"- {criterion}\\n\"\n",
    "    return message\n",
    "\n",
    "def generate_checkpoint_message(checks: List[LearningCheckpoint]) -> HumanMessage:\n",
    "    \"\"\"Generate a formatted message for learning checkpoints that need context.\n",
    "    \n",
    "    Args:\n",
    "        checks (List[LearningCheckpoint]): List of learning checkpoint objects\n",
    "        \n",
    "    Returns:\n",
    "        HumanMessage: Formatted message containing checkpoint descriptions, criteria and \n",
    "                     verification methods, ready for context search\n",
    "    \"\"\"\n",
    "    formatted_checks = []\n",
    "    \n",
    "    for check in checks:\n",
    "        checkpoint_text = f\"\"\"\n",
    "        Description: {check.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f'- {criterion}' for criterion in check.criteria)}\n",
    "        Verification Method: {check.verification}\n",
    "        \"\"\"\n",
    "        formatted_checks.append(checkpoint_text)\n",
    "    \n",
    "    all_checks = \"\\n---\\n\".join(formatted_checks)\n",
    "    \n",
    "    checkpoints_message = HumanMessage(content=f\"\"\"The following learning checkpoints need additional context:\n",
    "        {all_checks}\n",
    "        \n",
    "        Please generate search queries to find relevant information.\"\"\")\n",
    "    \n",
    "    return checkpoints_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93ad2d",
   "metadata": {},
   "source": [
    "## Prompt Configuration\n",
    "Here we will define core instructions prompts for our LLM. Each Message serves a specific purpose in the learning process.\n",
    "1. learning_checkpoint_generator: Creates structured learning milestones with clear criteria.\n",
    "2. checkpoint_based_query_generator: Generates targeted search queries for content retrieval.\n",
    "3. question_generator: Creates verification questions aligned with checkpoints.\n",
    "4. answer_verifier: Evaluates learner responses against success criteria.\n",
    "5. feyman_teacher: Crafts simplified explanations using Feynman technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292da258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
