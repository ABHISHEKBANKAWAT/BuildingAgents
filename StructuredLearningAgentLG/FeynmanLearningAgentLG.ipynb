{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f368e6e6",
   "metadata": {},
   "source": [
    "## Structured Learning Agent using LangGraph\n",
    "In this notebook, we will build a structured learning agent using LangGraph. The system will guide learners through a structured learning process of defined but customizable checkpoints. Verifying understanding at each step and providing feynman-style teaching when needed.\n",
    "\n",
    "## Motivation\n",
    "- Access to personalized 1:1 tutoring is expensive and not accessible to everyone.\n",
    "- Provide individualized learning experience to each learner and feedback 24/7.\n",
    "- Use own notes and web-retrieved content as context.\n",
    "- Offer patient, simple explanations of complex topics.\n",
    "\n",
    "## Key Components\n",
    "1. Learning State Graph: Orchestrates the sequential learning workflow.\n",
    "2. Checkpoint System: Defines structured learning milestones.\n",
    "3. Web Search Integration: Dynamically retrives relevant learning materials.\n",
    "4. Context Processing: Chunks and process learning materials.\n",
    "5. Question Generation: Creates checkpoint-specific verification questions.\n",
    "6. Understanding Verification: Evaluates learner comprehension with a clear threshold.\n",
    "7. Feynman-style Teaching: Provides patient, simple explanations of complex topics.\n",
    "\n",
    "## Method\n",
    "The system follows a structured learning cycle.\n",
    "1. Checkpoint Definition\n",
    "* Generate sequential learning milestones with clear success criteria.\n",
    "\n",
    "2. Context Building\n",
    "* Processes student-provided materials or retrieves relevant web content.\n",
    "3. Context Validation\n",
    "* Validates context based on checkpoint criteria.\n",
    "* Performs additional web searches if context doesn't meet criteria.\n",
    "4. Embedding Storage\n",
    "* Stores embeddings for retrieving only relevant chunks during verification.\n",
    "5. Understanding Verification\n",
    "* Generates checkpoint-specific questions.\n",
    "* Evaluates learner's answers against correct answers.\n",
    "* Provides clear feedback on understanding level.\n",
    "6. Progressive Learning\n",
    "* Advances to the next checkpoint when understanding is verified.\n",
    "* Provides Feynman-style teaching when needed.\n",
    "\n",
    "### Conclusion\n",
    "This structured learning agent provides a personalized, 24/7 learning experience. It can be easily extended to include additional features such as progress tracking, personalized recommendations, and more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cd3ad",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "#!pip install langchain-community langchain-openai langgraph pydantic python-dotenv semantic-chunkers semantic-router tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21583f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import operator\n",
    "import uuid\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import OpenAIEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f75768",
   "metadata": {},
   "source": [
    "Setup\n",
    "This agent is implemented using OpenAI's models, but can be used also with self-hosted LLM and embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a8a582",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m load_dotenv()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = os.getenv(\u001b[33m'\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m tavily_search = TavilySearchResults(max_results=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:721\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:781\u001b[39m, in \u001b[36mcheck_str\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1213a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
