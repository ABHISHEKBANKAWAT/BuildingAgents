{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f368e6e6",
   "metadata": {},
   "source": [
    "## Structured Learning Agent using LangGraph\n",
    "In this notebook, we will build a structured learning agent using LangGraph. The system will guide learners through a structured learning process of defined but customizable checkpoints. Verifying understanding at each step and providing feynman-style teaching when needed.\n",
    "\n",
    "## Motivation\n",
    "- Access to personalized 1:1 tutoring is expensive and not accessible to everyone.\n",
    "- Provide individualized learning experience to each learner and feedback 24/7.\n",
    "- Use own notes and web-retrieved content as context.\n",
    "- Offer patient, simple explanations of complex topics.\n",
    "\n",
    "## Key Components\n",
    "1. Learning State Graph: Orchestrates the sequential learning workflow.\n",
    "2. Checkpoint System: Defines structured learning milestones.\n",
    "3. Web Search Integration: Dynamically retrives relevant learning materials.\n",
    "4. Context Processing: Chunks and process learning materials.\n",
    "5. Question Generation: Creates checkpoint-specific verification questions.\n",
    "6. Understanding Verification: Evaluates learner comprehension with a clear threshold.\n",
    "7. Feynman-style Teaching: Provides patient, simple explanations of complex topics.\n",
    "\n",
    "## Method\n",
    "The system follows a structured learning cycle.\n",
    "1. Checkpoint Definition\n",
    "* Generate sequential learning milestones with clear success criteria.\n",
    "\n",
    "2. Context Building\n",
    "* Processes student-provided materials or retrieves relevant web content.\n",
    "3. Context Validation\n",
    "* Validates context based on checkpoint criteria.\n",
    "* Performs additional web searches if context doesn't meet criteria.\n",
    "4. Embedding Storage\n",
    "* Stores embeddings for retrieving only relevant chunks during verification.\n",
    "5. Understanding Verification\n",
    "* Generates checkpoint-specific questions.\n",
    "* Evaluates learner's answers against correct answers.\n",
    "* Provides clear feedback on understanding level.\n",
    "6. Progressive Learning\n",
    "* Advances to the next checkpoint when understanding is verified.\n",
    "* Provides Feynman-style teaching when needed.\n",
    "\n",
    "### Conclusion\n",
    "This structured learning agent provides a personalized, 24/7 learning experience. It can be easily extended to include additional features such as progress tracking, personalized recommendations, and more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cd3ad",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "#!pip install langchain-community langchain-openai langgraph pydantic python-dotenv semantic-chunkers semantic-router tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21583f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABHISHEK BANKAWAT\\Desktop\\BuildingAgents\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import operator\n",
    "import uuid\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import OpenAIEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f75768",
   "metadata": {},
   "source": [
    "Setup\n",
    "This agent is implemented using OpenAI's models, but can be used also with self-hosted LLM and embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a8a582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK BANKAWAT\\AppData\\Local\\Temp\\ipykernel_17044\\406296422.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1213a",
   "metadata": {},
   "source": [
    "## Data Models Definition\n",
    "We will define data structures for our adaptive learning system using pydantic models. These models type safety and provide clear structure for:\n",
    "* Learning goals and objectives\n",
    "* Checkpoint definitions and tracking\n",
    "* Search Queries for dynamic content.\n",
    "* Verification of learning progres.\n",
    "* Feynman teaching output format.\n",
    "* Question generation.\n",
    "\n",
    "Each model is designed to capture specific aspects of the learning process while maintaining type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c601b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Goals(BaseModel):\n",
    "    \"\"\" Structure for defining learning goals.\"\"\"\n",
    "    goals: str = Field(None, description=\"Learning goals\")\n",
    "\n",
    "class LearningCheckpoint(BaseModel):\n",
    "    \"\"\" Structure for a single checkpoint \"\"\"\n",
    "    description: str = Field(..., description=\"Main checkpoint description\")\n",
    "    criteria: List[str] = Field(...,description=\"List of success criteria\")\n",
    "    verification: str = Field(..., description=\"How to verify this checkpoint\")\n",
    "\n",
    "class Checkpoints(BaseModel):\n",
    "    \"\"\" Main checkpoints container with index tracking \"\"\"\n",
    "    checkpoints: List[LearningCheckpoint] = Field(\n",
    "        ...,\n",
    "        description=\"List of checkpoints covering foundation, applicationm and mastery levels\"\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\" Structure for search query collection\"\"\"\n",
    "    search_queries: list = Field(None, description=\"Search queries for retrievel.\")\n",
    "\n",
    "class LearningVerification(BaseModel):\n",
    "    \"\"\"Structure for verification results\"\"\"\n",
    "    understanding_level: float = Field(...,ge=0, le=1)\n",
    "    feedback: str\n",
    "    suggestions: List[str]\n",
    "    context_alignment:bool\n",
    "\n",
    "class FeynmanTeaching(BaseModel):\n",
    "    \"\"\" Structure for feynman teaching Method \"\"\"\n",
    "    simplified_explanation: str\n",
    "    KeyConcepts: List[str]\n",
    "    analogies: List[str]\n",
    "    \n",
    "class QuestionOutput(BaseModel):\n",
    "    \"\"\" Structure for question output \"\"\"\n",
    "    questions: str\n",
    "\n",
    "class InContext(BaseModel):\n",
    "    \"\"\" Structure for context verification \"\"\"\n",
    "    is_in_context: str = Field(..., description=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb58190",
   "metadata": {},
   "source": [
    "## Learning State Definition\n",
    "* The Learning topic and goals\n",
    "* Context and search results\n",
    "* Current progress through checkpoints\n",
    "* Verification results and teaching outputs\n",
    "* Current question-answer pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fe243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningtState(BaseModel):\n",
    "    topic: str\n",
    "    goals: List[str]\n",
    "    context: str\n",
    "    context_chunks: Annotated[list, operator.add]\n",
    "    context_key: str\n",
    "    search_queries: SearchQuery\n",
    "    checkpoints: Checkpoints\n",
    "    verifications: LearningVerification\n",
    "    teachings: FeynmanTeaching\n",
    "    current_checkpoint: int\n",
    "    current_question: QuestionOutput\n",
    "    current_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d8a5c",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "The system uses three utility functions:\n",
    "1. extract_content_from_chunks: Processes and combines text chunks into coherent content.\n",
    "2. Format_checkpoints_as_message: Converts checkpoint data into prompt format\n",
    "3. generate_checkpoint_message: Creates formatted message for context retrievel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_chunks(chunks):\n",
    "    \"\"\"Extract and combine content from chunks with splits attribute.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk objects that may contain splits attribute\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all chunks joined with newlines\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'splits') and chunk.splits:\n",
    "            chunk_content = ' '.join(chunk.splits)\n",
    "            content.append(chunk_content)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "def format_checkpoints_as_message(checkpoints: Checkpoints) -> str:\n",
    "    \"\"\"Convert Checkpoints object to a formatted string for the message.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints (Checkpoints): Checkpoints object containing learning checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing numbered checkpoints with descriptions and criteria\n",
    "    \"\"\"\n",
    "    message = \"Here are the learning checkpoints:\\n\\n\"\n",
    "    for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "        message += f\"Checkpoint {i}:\\n\"\n",
    "        message += f\"Description: {checkpoint.description}\\n\"\n",
    "        message += \"Success Criteria:\\n\"\n",
    "        for criterion in checkpoint.criteria:\n",
    "            message += f\"- {criterion}\\n\"\n",
    "    return message\n",
    "\n",
    "def generate_checkpoint_message(checks: List[LearningCheckpoint]) -> HumanMessage:\n",
    "    \"\"\"Generate a formatted message for learning checkpoints that need context.\n",
    "    \n",
    "    Args:\n",
    "        checks (List[LearningCheckpoint]): List of learning checkpoint objects\n",
    "        \n",
    "    Returns:\n",
    "        HumanMessage: Formatted message containing checkpoint descriptions, criteria and \n",
    "                     verification methods, ready for context search\n",
    "    \"\"\"\n",
    "    formatted_checks = []\n",
    "    \n",
    "    for check in checks:\n",
    "        checkpoint_text = f\"\"\"\n",
    "        Description: {check.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f'- {criterion}' for criterion in check.criteria)}\n",
    "        Verification Method: {check.verification}\n",
    "        \"\"\"\n",
    "        formatted_checks.append(checkpoint_text)\n",
    "    \n",
    "    all_checks = \"\\n---\\n\".join(formatted_checks)\n",
    "    \n",
    "    checkpoints_message = HumanMessage(content=f\"\"\"The following learning checkpoints need additional context:\n",
    "        {all_checks}\n",
    "        \n",
    "        Please generate search queries to find relevant information.\"\"\")\n",
    "    \n",
    "    return checkpoints_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93ad2d",
   "metadata": {},
   "source": [
    "## Prompt Configuration\n",
    "Here we will define core instructions prompts for our LLM. Each Message serves a specific purpose in the learning process.\n",
    "1. learning_checkpoint_generator: Creates structured learning milestones with clear criteria.\n",
    "2. checkpoint_based_query_generator: Generates targeted search queries for content retrieval.\n",
    "3. question_generator: Creates verification questions aligned with checkpoints.\n",
    "4. answer_verifier: Evaluates learner responses against success criteria.\n",
    "5. feyman_teacher: Crafts simplified explanations using Feynman technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292da258",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_checkpoints_generator = SystemMessage(content=\"\"\"You will be given a learning topic title and learning objectives.\n",
    "Your goal is to generate clear learning checkpoints that will help verify understanding and progress through the topic.\n",
    "The output should be in the following dictionary structure:\n",
    "checkpoint \n",
    "-> description (level checkpoint description)\n",
    "-> criteria\n",
    "-> verification (How to verify this checkpoint (Feynman Methods))\n",
    "Requirements for each checkpoint:\n",
    "- Description should be clear and concise\n",
    "- Criteria should be specific and measurable (3-5 items)\n",
    "- Verification method should be practical and appropriate for the level\n",
    "- Verification will be checked by language model, so it must by in natural language\n",
    "- All elements should align with the learning objectives\n",
    "- Use action verbs and clear language\n",
    "Ensure all checkpoints progress logically from foundation to mastery.\n",
    "IMPORTANT - ANSWER ONLY 3 CHECKPOINTS\"\"\")\n",
    "\n",
    "checkpoint_based_query_generator = SystemMessage(content=\"\"\"You will be given learning checkpoints for a topic.\n",
    "Your goal is to generate search queries that will retrieve content matching each checkpoint's requirements from retrieval systems or web search.\n",
    "Follow these steps:\n",
    "1. Analyze each learning checkpoint carefully\n",
    "2. For each checkpoint, generate ONE targeted search query that will retrieve:\n",
    "   - Content for checkpoint verification\"\"\")\n",
    "\n",
    "validate_context = SystemMessage(content=\"\"\"You will be given a learning criteria and context.\n",
    "Check if the the criteria could be answered using the context.\n",
    "Always answer YES or NO\"\"\")\n",
    "\n",
    "question_generator = SystemMessage(content=\"\"\"You will be given a checkpoint description, success criteria, and verification method.\n",
    "Your goal is to generate an appropriate question that aligns with the checkpoint's verification requirements.\n",
    "The question should:\n",
    "1. Follow the specified verification method\n",
    "2. Cover all success criteria\n",
    "3. Encourage demonstration of understanding\n",
    "4. Be clear and specific\n",
    "Output should be a single, well-formulated question that effectively tests the checkpoint's learning objectives.\"\"\")\n",
    "\n",
    "answer_verifier = SystemMessage(content=\"\"\"You will be given a student's answer, question, checkpoint details, and relevant context.\n",
    "Your goal is to analyze the answer against the checkpoint criteria and provided context.\n",
    "Analyze considering:\n",
    "1. Alignment with verification method specified\n",
    "2. Coverage of all success criteria\n",
    "3. Use of relevant concepts from context\n",
    "4. Depth and accuracy of understanding\n",
    "Output should include:\n",
    "- understanding_level: float between 0 and 1\n",
    "- feedback: detailed explanation of the assessment\n",
    "- suggestions: list of specific improvements\n",
    "- context_alignment: boolean indicating if the answer aligns with provided context\"\"\")\n",
    "\n",
    "feynman_teacher = SystemMessage(content=\"\"\"You will be given verification results, checkpoint criteria, and learning context.\n",
    "Your goal is to create a Feynman-style teaching explanation for concepts that need reinforcement.\n",
    "The explanation should include:\n",
    "1. Simplified explanation without technical jargon\n",
    "2. Concrete, relatable analogies\n",
    "3. Key concepts to remember\n",
    "Output should follow the Feynman technique:\n",
    "- simplified_explanation: clear, jargon-free explanation\n",
    "- key_concepts: list of essential points\n",
    "- analogies: list of relevant, concrete comparisons\n",
    "Focus on making complex ideas accessible and memorable.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedc52c",
   "metadata": {},
   "source": [
    "## Context Storage\n",
    "The ContextStore class manages context chunks and embeddings in memory, optimizing token usage by allowing access to only relevant context during answer verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b3867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextStore:\n",
    "    \"\"\"Store for managing context chunks and their embeddings in memory.\n",
    "    \n",
    "    A class that provides storage and retrieval of context data using an in-memory store.\n",
    "    Each context entry consists of context chunks and their corresponding embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ContextStore with an empty in-memory store.\"\"\"\n",
    "        self.store = InMemoryStore()\n",
    "        \n",
    "    def save_context(self, context_chunks: list, embeddings: list, key: str = None):\n",
    "        \"\"\"Save context chunks and their embeddings to the store.\n",
    "        \n",
    "        Args:\n",
    "            context_chunks (list): List of context chunk objects\n",
    "            embeddings (list): List of corresponding embeddings for the chunks\n",
    "            key (str, optional): Custom key for storing the context. Defaults to None,\n",
    "                               in which case a UUID is generated.\n",
    "            \n",
    "        Returns:\n",
    "            str: The key used to store the context\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        \n",
    "        if key is None:\n",
    "            key = str(uuid.uuid4())\n",
    "            \n",
    "        value = {\n",
    "            \"chunks\": context_chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "        \n",
    "        self.store.put(namespace, key, value)\n",
    "        return key\n",
    "        \n",
    "    def get_context(self, context_key: str):\n",
    "        \"\"\"Retrieve context data from the store using a key.\n",
    "        \n",
    "        Args:\n",
    "            context_key (str): The key used to store the context\n",
    "            \n",
    "        Returns:\n",
    "            dict: The stored context value containing chunks and embeddings\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        memory = self.store.get(namespace, context_key)\n",
    "        return memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3d597",
   "metadata": {},
   "source": [
    "### Core Learning System Functions\n",
    "The learning system is powered by eight main functions that process and update the LearningState:\n",
    "\n",
    "### Content Generation and Processing\n",
    "1. generate_checkpoints: Creates learning milestones from topic and goals\n",
    "2. generate_query: Formulates checkpoint-based search queries\n",
    "3. search_web: Retrieves content via Tavilysearch\n",
    "4. chunk_context: Segments learning materials\n",
    "5. context_validation: Ensures context meets checkpoint requirements\n",
    "\n",
    "### Learning Verification and Support\n",
    "6. generate_question: Creates verification questions\n",
    "7. verify_answer: Evaluates against checkpoint criteria\n",
    "teach_concept: Provides Feynman-style explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba671c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cfd4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(state: LearningtState):\n",
    "    \"\"\"Generates search queries based on learning checkpoints from current state.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery) \n",
    "    checkpoints_message = HumanMessage(content=format_checkpoints_as_message(state['checkpoints']))  \n",
    "    messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "    search_queries = structured_llm.invoke(messages)\n",
    "    return {\"search_queries\": search_queries}\n",
    "\n",
    "def search_web(state: LearningtState):\n",
    "    \"\"\"Retrieves and processes web search results based on search queries.\"\"\"\n",
    "    search_queries = state[\"search_queries\"].search_queries\n",
    "    \n",
    "    all_search_docs = []\n",
    "    for query in search_queries:\n",
    "        search_docs = tavily_search.invoke(query)\n",
    "        all_search_docs.extend(search_docs)\n",
    "    \n",
    "    formatted_search_docs = [\n",
    "        f'Context: {doc[\"content\"]}\\n Source: {doc[\"url\"]}\\n'\n",
    "        for doc in all_search_docs\n",
    "    ]\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(formatted_search_docs)\n",
    "    context_key = context_store.save_context(\n",
    "        formatted_search_docs,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    \n",
    "    return {\"context_chunks\": formatted_search_docs}\n",
    "\n",
    "def generate_checkpoints(state: LearningtState):\n",
    "    \"\"\"Creates learning checkpoints based on given topic and goals.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(Checkpoints)\n",
    "    messages = [\n",
    "        learning_checkpoints_generator,\n",
    "        SystemMessage(content=f\"Topic: {state['topic']}\"),\n",
    "        SystemMessage(content=f\"Goals: {', '.join(str(goal) for goal in state['goals'])}\")\n",
    "    ]\n",
    "    checkpoints = structured_llm.invoke(messages)\n",
    "    return {\"checkpoints\": checkpoints}\n",
    "\n",
    "def chunk_context(state: LearningtState):\n",
    "    \"\"\"Splits context into manageable chunks and generates their embeddings.\"\"\"\n",
    "    encoder = OpenAIEncoder(name=\"text-embedding-3-large\")\n",
    "    chunker = StatisticalChunker(\n",
    "        encoder=encoder,\n",
    "        min_split_tokens=128,\n",
    "        max_split_tokens=512\n",
    "    )\n",
    "    \n",
    "    chunks = chunker([state['context']])\n",
    "    content = []\n",
    "    for chunk in chunks:\n",
    "        content.append(extract_content_from_chunks(chunk))\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(content)\n",
    "    context_key = context_store.save_context(\n",
    "        content,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    return {\"context_chunks\": content, \"context_key\": context_key}\n",
    "\n",
    "def context_validation(state: LearningtState):\n",
    "    \"\"\"Validates context coverage against checkpoint criteria using stored embeddings.\"\"\"\n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    checks = []\n",
    "    structured_llm = llm.with_structured_output(InContext)\n",
    "    \n",
    "    for checkpoint in state['checkpoints'].checkpoints:\n",
    "        query = embeddings.embed_query(checkpoint.verification)\n",
    "        \n",
    "        similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "        top_3_indices = sorted(range(len(similarities)), \n",
    "                             key=lambda i: similarities[i], \n",
    "                             reverse=True)[:3]\n",
    "        relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "        \n",
    "        messages = [\n",
    "            validate_context,\n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Criteria:\n",
    "            {chr(10).join(f\"- {c}\" for c in checkpoint.criteria)}\n",
    "            \n",
    "            Context:\n",
    "            {chr(10).join(relevant_chunks)}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = structured_llm.invoke(messages)\n",
    "        if response.is_in_context.lower() == \"no\":\n",
    "            checks.append(checkpoint)\n",
    "    \n",
    "    if checks:\n",
    "        structured_llm = llm.with_structured_output(SearchQuery)\n",
    "        checkpoints_message = generate_checkpoint_message(checks)\n",
    "        \n",
    "        messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "        search_queries = structured_llm.invoke(messages)\n",
    "        return {\"search_queries\": search_queries}\n",
    "    \n",
    "    return {\"search_queries\": None}\n",
    "\n",
    "def generate_question(state: LearningtState):\n",
    "    \"\"\"Generates assessment questions based on current checkpoint verification requirements.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(QuestionOutput)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        question_generator,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Generate an appropriate verification question.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    question_output = structured_llm.invoke(messages)\n",
    "    return {\"current_question\": question_output.question}\n",
    "\n",
    "def verify_answer(state: LearningtState):\n",
    "    \"\"\"Evaluates user answers against checkpoint criteria using relevant context chunks.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningVerification)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    query = embeddings.embed_query(checkpoint_info.verification)\n",
    "    \n",
    "    similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "    top_3_indices = sorted(range(len(similarities)), \n",
    "                         key=lambda i: similarities[i], \n",
    "                         reverse=True)[:3]\n",
    "    relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "    \n",
    "    messages = [\n",
    "        answer_verifier,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Question: {state['current_question']}\n",
    "        Answer: {state['current_answer']}\n",
    "        \n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Context:\n",
    "        {chr(10).join(relevant_chunks)}\n",
    "        \n",
    "        Assess the answer.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    verification = structured_llm.invoke(messages)\n",
    "    return {\"verifications\": verification}\n",
    "    \n",
    "def teach_concept(state: LearningtState):\n",
    "    \"\"\"Creates simplified Feynman-style explanations for concepts that need reinforcement.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(FeynmanTeaching)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        feynman_teacher,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Criteria: {checkpoint_info.criteria}\n",
    "        Verification: {state['verifications']}\n",
    "        \n",
    "        Context:\n",
    "        {state['context_chunks']}\n",
    "        \n",
    "        Create a Feynman teaching explanation.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    teaching = structured_llm.invoke(messages)\n",
    "    return {\"teachings\": teaching}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633617e6",
   "metadata": {},
   "source": [
    "## Helper State Management Functions\n",
    "Here we define two auxiliary functions that manage the learning flow:\n",
    "\n",
    "1. user_answer: Placeholder for collecting user responses to verification questions\n",
    "2. next_checkpoint: Increments the checkpoint counter to progress through learning milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5667759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_answer(state: LearningtState):\n",
    "    \"\"\"Placeholder for handling user's answer input.\"\"\"\n",
    "    pass\n",
    "\n",
    "def next_checkpoint(state: LearningtState):\n",
    "    \"\"\"Advances to the next checkpoint in the learning sequence.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint'] + 1\n",
    "    return {'current_checkpoint': current_checkpoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e23747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7eef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d55e01",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
