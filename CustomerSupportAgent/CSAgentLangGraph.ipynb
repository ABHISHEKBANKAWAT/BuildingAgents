{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d9a3a3",
   "metadata": {},
   "source": [
    "# Building an Intelligent Customer Support Agent with LangGraph\n",
    "## Overview\n",
    "We will create a intelligent customer support agent using langgraph, a powerful tool for building complex language model workflows. The agent is designed to categorize customer queries, analyze sentiment, and provide appropriate responses or escalate issues when necessary\n",
    "\n",
    "## Key Component\n",
    "1. State Management - Using TypedDict to define and manage the state of each customer interaction.\n",
    "2. Query Categorization - Classifying customer queries into Technical, Billing, or general categories.\n",
    "3. Sentiment Analysis - Determining the emotional tone of customer queries.\n",
    "4. Response Generation - Creating appropriate responses based on the query category and sentiment.\n",
    "5. Escalation Mechanism - Automatically escalating queries with negative sentiment to human agents.\n",
    "6. Workflow Graph - Utilizing Langgraph to create a flexible and extensible workflow\n",
    "\n",
    "## Method Details \n",
    "1. Initialization - Set up env and import necessary libraries\n",
    "2. State Definition - Create a structure to hold query info, category, sentiment and response.\n",
    "3. Node functions - Implement seprate functions for categorization, sentiment analysis, response generation and escalation.\n",
    "4. Graph Construction - Use StateGraph to define the workflow, adding nodes and edges to represent the support process.\n",
    "5. Conditional Routing - Implement logic to route queries to appropriate nodes based on category and sentiment.\n",
    "6. Workflow Compilation - Compile the graph into a callable workflow.\n",
    "7. Execution - Process customer queries through the workflow and generate responses.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15764cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langgraph langchain-core langchain-openai python-dotenv ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97eebf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7659c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    sentiment: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(state: State) -> State:\n",
    "    \"\"\"Categorize the customer query into Technical, Billing, or General.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following customer query into one of these categories: \"\n",
    "        \"Technical, Billing, General. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGoogleGenerativeAI(temperature=0)\n",
    "    category = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": category}\n",
    "\n",
    "def analyze_sentiment(state: State) -> State:\n",
    "    \"\"\"Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the sentiment of the following customer query. \"\n",
    "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGoogleGenerativeAI(temperature=0)\n",
    "    sentiment = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"sentiment\": sentiment}\n",
    "\n",
    "def handle_technical(state: State) -> State:\n",
    "    \"\"\"Provide a technical support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a technical support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGoogleGenerativeAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def handle_billing(state: State) -> State:\n",
    "    \"\"\"Provide a billing support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a billing support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGoogleGenerativeAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def handle_general(state: State) -> State:\n",
    "    \"\"\"Provide a general support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a general support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGoogleGenerativeAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def escalate(state: State) -> State:\n",
    "    \"\"\"Escalate the query to a human agent due to negative sentiment.\"\"\"\n",
    "    return {\"response\": \"This query has been escalated to a human agent due to its negative sentiment.\"}\n",
    "\n",
    "def route_query(state: State) -> str:\n",
    "    \"\"\"Route the query based on its sentiment and category.\"\"\"\n",
    "    if state[\"sentiment\"] == \"Negative\":\n",
    "        return \"escalate\"\n",
    "    elif state[\"category\"] == \"Technical\":\n",
    "        return \"handle_technical\"\n",
    "    elif state[\"category\"] == \"Billing\":\n",
    "        return \"handle_billing\"\n",
    "    else:\n",
    "        return \"handle_general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a86b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2271ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c28477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
